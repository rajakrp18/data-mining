# -*- coding: utf-8 -*-
"""Employee dataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uoXL3q51uLRFlz90kdN8OMwbNxPnTko8

#Employee dataset Classification

#Step 1: Load and Explore the Dataset
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
from sklearn.preprocessing import LabelEncoder, StandardScaler

# Load dataset
df = pd.read_csv("Employee.csv")  # Ensure the file path is correct

# Display basic dataset info
print("Dataset Information:\n", df.info())
print("\nFirst 5 Rows:\n", df.head())

"""#Step 2: Handle Missing Values"""

# Fill missing numerical values with median
df.fillna(df.median(numeric_only=True), inplace=True)

# Fill missing categorical values with mode
for col in df.select_dtypes(include=["object"]).columns:
    df[col].fillna(df[col].mode()[0], inplace=True)

"""#Step 3: Encode Categorical Variables"""

label_encoders = {}
for col in df.select_dtypes(include=["object"]).columns:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])
    label_encoders[col] = le

print(df.columns)  # Lists all column names

"""#Step 4: Split Dataset into Train, Test, and Validation Sets"""

# Define features (X) and target variable (y)
target_column = "LeaveOrNot"  # Target column identified from the dataset
X = df.drop(columns=[target_column])  # Features
y = df[target_column]  # Target variable

# Split data into Train (70%), Validation (15%), Test (15%)
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

print("Train Set:", X_train.shape)
print("Validation Set:", X_val.shape)
print("Test Set:", X_test.shape)

# Define features (X) and target variable (y)
X = df.drop(columns=["Target_Column"])  # Replace "Target_Column" with the actual target column
y = df["Target_Column"]

# Split data into Train (70%), Validation (15%), Test (15%)
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

print("Train Set:", X_train.shape)
print("Validation Set:", X_val.shape)
print("Test Set:", X_test.shape)

"""#Step 5: Feature Scaling"""

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_val = scaler.transform(X_val)
X_test = scaler.transform(X_test)

"""#Step 6: Train a Random Forest Model"""

rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Predictions
y_val_pred = rf_model.predict(X_val)

# Model Evaluation
accuracy = accuracy_score(y_val, y_val_pred)
print("\nValidation Accuracy:", accuracy)
print("\nClassification Report:\n", classification_report(y_val, y_val_pred))

"""Step 7: Final Model Testing"""

y_test_pred = rf_model.predict(X_test)
test_accuracy = accuracy_score(y_test, y_test_pred)
print("\nTest Accuracy:", test_accuracy)

import seaborn as sns
import matplotlib.pyplot as plt

sns.boxplot(x=df['LeaveOrNot'], y=df['ExperienceInCurrentDomain'])
plt.title("Experience vs Attrition")
plt.show()

sns.countplot(x=df['PaymentTier'], hue=df['LeaveOrNot'])
plt.title("Attrition Rate by Payment Tier")
plt.show()

sns.countplot(x=df['Gender'], hue=df['LeaveOrNot'])
plt.title("Attrition Rate by Gender")
plt.show()

plt.figure(figsize=(10,5))
sns.countplot(x=df['City'], hue=df['LeaveOrNot'])
plt.xticks(rotation=45)
plt.title("Attrition by City")
plt.show()